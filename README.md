# cpt-categorizer

[![CCDS Project Template](https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter)](https://cookiecutter-data-science.drivendata.org/)

An automated categorization of unstandardized Philippine CPT descriptions using the OpenAI API.

---

## ğŸ“ Project Organization

```
â”œâ”€â”€ LICENSE            <- Open-source license if one is chosen
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”œâ”€â”€ docs               <- Project documentation and visual references
â”‚
â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks (e.g., `1.0-jme-cpt-parsing-analysis.ipynb`)
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration and tool integration for `cpt_categorizer`
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8 and other linters
â”‚
â”œâ”€â”€ references         <- Data dictionaries, schema snapshots, schema version logs, and manuals
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures for reporting
â”‚
â””â”€â”€ cpt_categorizer    <- Source code
    â”œâ”€â”€ __init__.py             <- Initializes the Python module
    â”œâ”€â”€ config.py               <- Stores shared configurations
    â”œâ”€â”€ dataset.py              <- Ingests or prepares datasets
    â”œâ”€â”€ features.py             <- Feature extraction and transformation
    â”œâ”€â”€ modeling
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ predict.py          <- Model inference logic
    â”‚   â””â”€â”€ train.py            <- Model training logic
    â”œâ”€â”€ plots.py                <- Visualization utilities
    â””â”€â”€ agents
        â”œâ”€â”€ parsing.py          <- Logic for Parsing Agent
        â”œâ”€â”€ tagging.py          <- Tagging Agent implementation
        â”œâ”€â”€ normalization.py    <- Normalizer Agent logic
        â”œâ”€â”€ scoring.py          <- Scoring Agent
        â”œâ”€â”€ compliance.py       <- Schema Compliance Agent
        â”œâ”€â”€ logging.py          <- Logging & Feedback Agent
        â”œâ”€â”€ correction.py       <- Correction Agent
        â”œâ”€â”€ evolution.py        <- Schema Evolution Agent
        â””â”€â”€ versioning.py       <- Schema Version Tracker
```

---

## ğŸ§  AI Agent Framework Overview

This project uses a modular AI agent framework to classify unstandardized CPT phrases. Each agent performs a specific role in the classification pipeline. For full descriptions and agent responsibilities, see [`docs/agent_roles.md`](docs/agent_roles.md).

**Key Agent Roles:**

* **Parsing Agent**: Cleans and prepares raw CPT phrases
* **Tagging Agent**: Identifies Sections, Subsections, and candidate detail tags
* **Normalizer Agent**: Standardizes and schema-aligns detail tags
* **Scoring Agent**: Assigns confidence levels to each tag and classification
* **Schema Compliance Agent**: Validates against current schema and formatting rules
* **Logging & Feedback Agent**: Captures failures and borderline cases
* **Correction Agent**: Applies manual corrections and stores retraining data
* **Schema Evolution Agent**: Proposes updates to schema based on real-world use
* **Schema Version Tracker**: Maintains snapshots and traceability for schema changes

### âš™ï¸ Key Schema Files

* `cpt_detail.json` â€” Valid detail dimensions and tag values
* `cpt_section_subsection.json` â€” Allowed sections and subsections
* `cpt_detail_rule.json` â€” Formatting, spelling, and normalization rules
* Schema snapshots and logs stored in `references/`

---

## ğŸ” Agent Interaction Flow

```
1. Raw CPT Description â†’ Parsing Agent
2. Parsing Agent â†’ cleans â†’ Tagging Agent
3. Tagging Agent â†’ identifies tags â†’ Normalizer Agent
4. Normalizer Agent â†’ standardizes â†’ Scoring Agent
5. Scoring Agent â†’ scores â†’ Schema Compliance Agent
6. Schema Compliance Agent:
   - If valid â†’ Final Output Generator
   - If invalid â†’ Logging & Feedback Agent
7. Logging & Feedback Agent â†’ Correction Agent
8. Correction Agent â†’ Schema Evolution Agent
9. Schema Evolution Agent â†’ loops back to Schema Compliance Agent
```

---

## ğŸ“¤ Final Output

* Validated and classified CPT record with:

  * Section, Subsection, Details
  * Confidence scores
  * Schema version ID
* Exported as CSV, JSON, or database row

---

## âœ… Status

This project is in development. Schema proposals, rule evolution, and scoring logic are actively evolving with production feedback.